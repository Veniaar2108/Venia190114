{ 
 "cells": [ 
 { 
 "cell_type": "markdown", 
 "metadata": {}, 
 "source": [ 
 "# Program OCR untuk Ekstraksi Kandungan Gizi pada Kemasan Minuman Berpemanis\n", 
 "Program ini menggunakan U-Net dan Tesseract untuk mengekstraksi informasi kandungan gizi dari kemasan minuman.\n", 
 "\n", 
 "## Tahapan Proses:\n", 
 "1. Input image\n", 
 "2. Resize 572 x 572\n", 
 "3. Split dataset (70 train, 20 test, 10 validation)\n", 
 "4. U-Net - tesseract (U-Net - Connected Component Analysis - Find Lines and Words - Word Classification - Word List - Final Word Output)\n", 
 "5. Parsing regex untuk ekstraksi kandungan gizi\n", 
 "6. Save Result\n", 
 "7. Compare with Ground Truth (dataset-mbdk-new.csv)\n", 
 "8. Evaluation system" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# 1. Input Image - Import library dan load gambar\n", 
 "import cv2\n", 
 "import numpy as np\n", 
 "import matplotlib.pyplot as plt\n", 
 "from PIL import Image\n", 
 "import os\n", 
 "import glob\n", 
 "\n", 
 "def load_images_from_folder(folder_path):\n", 
 "    \"\"\"\n", 
 "    Load images from specified folder\n", 
 "    \"\"\"\n", 
 "    images = []\n", 
 "    image_paths = []\n", 
 "    \n", 
 "    # Supported image formats\n", 
 "    extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']\n", 
 "    \n", 
 "    for extension in extensions:\n", 
 "        for image_path in glob.glob(os.path.join(folder_path, extension)):\n", 
 "            try:\n", 
 "                img = cv2.imread(image_path)\n", 
 "                if img is not None:\n", 
 "                    images.append(img)\n", 
 "                    image_paths.append(image_path)\n", 
 "                    print(f\"Loaded: {os.path.basename(image_path)}\")\n", 
 "            except Exception as e:\n", 
 "                print(f\"Error loading {image_path}: {e}\")\n", 
 "    \n", 
 "    print(f\"Total images loaded: {len(images)}\")\n", 
 "    return images, image_paths\n", 
 "\n", 
 "# Example usage\n", 
 "# images, image_paths = load_images_from_folder('path/to/your/images')\n", 
 "\n", 
 "# Display sample image\n", 
 "def display_image(image, title=\"Image\"):\n", 
 "    plt.figure(figsize=(10, 8))\n", 
 "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n", 
 "    plt.title(title)\n", 
 "    plt.axis('off')\n", 
 "    plt.show()\n", 
 "\n", 
 "print(\"Step 1: Input Image - Ready\")" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# 2. Resize Image to 572 x 572\n", 
 "def resize_image_572(image):\n", 
 "    \"\"\"\n", 
 "    Resize image to 572x572 pixels while maintaining aspect ratio\n", 
 "    \"\"\"\n", 
 "    # Get original dimensions\n", 
 "    height, width = image.shape[:2]\n", 
 "    \n", 
 "    # Calculate aspect ratio\n", 
 "    aspect_ratio = width / height\n", 
 "    \n", 
 "    # Resize to 572x572\n", 
 "    target_size = 572\n", 
 "    \n", 
 "    if aspect_ratio > 1:  # Width > Height\n", 
 "        new_width = target_size\n", 
 "        new_height = int(target_size / aspect_ratio)\n", 
 "    else:  # Height >= Width\n", 
 "        new_height = target_size\n", 
 "        new_width = int(target_size * aspect_ratio)\n", 
 "    \n", 
 "    # Resize image\n", 
 "    resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n", 
 "    \n", 
 "    # Create 572x572 canvas and center the image\n", 
 "    canvas = np.zeros((target_size, target_size, 3), dtype=np.uint8)\n", 
 "    y_offset = (target_size - new_height) // 2\n", 
 "    x_offset = (target_size - new_width) // 2\n", 
 "    \n", 
 "    canvas[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = resized\n", 
 "    \n", 
 "    return canvas\n", 
 "\n", 
 "def resize_all_images(images):\n", 
 "    \"\"\"\n", 
 "    Resize all images to 572x572\n", 
 "    \"\"\"\n", 
 "    resized_images = []\n", 
 "    for i, img in enumerate(images):\n", 
 "        resized = resize_image_572(img)\n", 
 "        resized_images.append(resized)\n", 
 "        if i % 10 == 0:\n", 
 "            print(f\"Resized {i+1}/{len(images)} images\")\n", 
 "    \n", 
 "    print(f\"All {len(resized_images)} images resized to 572x572\")\n", 
 "    return resized_images\n", 
 "\n", 
 "# Example usage\n", 
 "# resized_images = resize_all_images(images)\n", 
 "\n", 
 "print(\"Step 2: Resize to 572x572 - Ready\")" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# 3. Split Dataset (70% train, 20% test, 10% validation)\n", 
 "from sklearn.model_selection import train_test_split\n", 
 "import random\n", 
 "\n", 
 "def split_dataset(images, labels=None, train_ratio=0.7, test_ratio=0.2, val_ratio=0.1):\n", 
 "    \"\"\"\n", 
 "    Split dataset into train, test, and validation sets\n", 
 "    \"\"\"\n", 
 "    assert abs(train_ratio + test_ratio + val_ratio - 1.0) < 1e-6, \"Ratios must sum to 1.0\"\n", 
 "    \n", 
 "    # If no labels provided, create dummy labels\n", 
 "    if labels is None:\n", 
 "        labels = list(range(len(images)))\n", 
 "    \n", 
 "    # First split: separate training set\n", 
 "    X_train, X_temp, y_train, y_temp = train_test_split(\n", 
 "        images, labels, \n", 
 "        test_size=(1 - train_ratio), \n", 
 "        random_state=42,\n", 
 "        shuffle=True\n", 
 "    )\n", 
 "    \n", 
 "    # Second split: separate test and validation from temp\n", 
 "    test_val_ratio = test_ratio / (test_ratio + val_ratio)\n", 
 "    X_test, X_val, y_test, y_val = train_test_split(\n", 
 "        X_temp, y_temp,\n", 
 "        test_size=(1 - test_val_ratio),\n", 
 "        random_state=42,\n", 
 "        shuffle=True\n", 
 "    )\n", 
 "    \n", 
 "    print(f\"Dataset split completed:\")\n", 
 "    print(f\"Training set: {len(X_train)} images ({len(X_train)/len(images)*100:.1f}%)\")\n", 
 "    print(f\"Test set: {len(X_test)} images ({len(X_test)/len(images)*100:.1f}%)\")\n", 
 "    print(f\"Validation set: {len(X_val)} images ({len(X_val)/len(images)*100:.1f}%)\")\n", 
 "    \n", 
 "    return {\n", 
 "        'train': {'images': X_train, 'labels': y_train},\n", 
 "        'test': {'images': X_test, 'labels': y_test},\n", 
 "        'val': {'images': X_val, 'labels': y_val}\n", 
 "    }\n", 
 "\n", 
 "# Example usage\n", 
 "# dataset_split = split_dataset(resized_images)\n", 
 "\n", 
 "print(\"Step 3: Dataset Split - Ready\")" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# 4. U-Net + Tesseract OCR Pipeline\n", 
 "import tensorflow as tf\n", 
 "from tensorflow.keras import layers, models\n", 
 "import pytesseract\n", 
 "from scipy import ndimage\n", 
 "from skimage import measure, morphology\n", 
 "\n", 
 "# U-Net Architecture\n", 
 "def unet_model(input_size=(572, 572, 3)):\n", 
 "    \"\"\"\n", 
 "    Build U-Net model for text segmentation\n", 
 "    \"\"\"\n", 
 "    inputs = tf.keras.Input(input_size)\n", 
 "    \n", 
 "    # Encoder\n", 
 "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n", 
 "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n", 
 "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n", 
 "    \n", 
 "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n", 
 "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n", 
 "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n", 
 "    \n", 
 "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n", 
 "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n", 
 "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n", 
 "    \n", 
 "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n", 
 "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n", 
 "    drop4 = layers.Dropout(0.5)(conv4)\n", 
 "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n", 
 "    \n", 
 "    # Bridge\n", 
 "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n", 
 "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n", 
 "    drop5 = layers.Dropout(0.5)(conv5)\n", 
 "    \n", 
 "    # Decoder\n", 
 "    up6 = layers.Conv2D(512, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(drop5))\n", 
 "    merge6 = layers.concatenate([drop4, up6], axis=3)\n", 
 "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(merge6)\n", 
 "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n", 
 "    \n", 
 "    up7 = layers.Conv2D(256, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv6))\n", 
 "    merge7 = layers.concatenate([conv3, up7], axis=3)\n", 
 "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)\n", 
 "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n", 
 "    \n", 
 "    up8 = layers.Conv2D(128, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv7))\n", 
 "    merge8 = layers.concatenate([conv2, up8], axis=3)\n", 
 "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)\n", 
 "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n", 
 "    \n", 
 "    up9 = layers.Conv2D(64, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv8))\n", 
 "    merge9 = layers.concatenate([conv1, up9], axis=3)\n", 
 "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)\n", 
 "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n", 
 "    conv9 = layers.Conv2D(2, 3, activation='relu', padding='same')(conv9)\n", 
 "    \n", 
 "    # Output layer\n", 
 "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv9)\n", 
 "    \n", 
 "    model = models.Model(inputs=inputs, outputs=outputs)\n", 
 "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n", 
 "    \n", 
 "    return model\n", 
 "\n", 
 "def connected_component_analysis(binary_image):\n", 
 "    \"\"\"\n", 
 "    Perform connected component analysis\n", 
 "    \"\"\"\n", 
 "    labeled_image = measure.label(binary_image)\n", 
 "    regions = measure.regionprops(labeled_image)\n", 
 "    return labeled_image, regions\n", 
 "\n", 
 "def find_lines_and_words(regions):\n", 
 "    \"\"\n", 
 "    Group connected components into lines and words\n", 
 "    \"\"\n", 
 "    # Sort regions by y-coordinate (top to bottom)\n", 
 "    regions = sorted(regions, key=lambda r: r.centroid[0])\n", 
 "    \n", 
 "    lines = []\n", 
 "    current_line = []\n", 
 "    current_y = None\n", 
 "    \n", 
 "    for region in regions:\n", 
 "        y = region.centroid[0]\n", 
 "        \n", 
 "        if current_y is None or abs(y - current_y) < 20:  # Same line threshold\n", 
 "            current_line.append(region)\n", 
 "            current_y = y\n", 
 "        else:\n", 
 "            if current_line:\n", 
 "                lines.append(sorted(current_line, key=lambda r: r.centroid[1]))  # Sort by x-coordinate\n", 
 "            current_line = [region]\n", 
 "            current_y = y\n", 
 "    \n", 
 "    if current_line:\n", 
 "        lines.append(sorted(current_line, key=lambda r: r.centroid[1]))\n", 
 "    \n", 
 "    return lines\n", 
 "\n", 
 "def ocr_with_unet_pipeline(image, model=None):\n", 
 "    \"\"\"\n", 
 "    Complete OCR pipeline with U-Net preprocessing\n", 
 "    \"\"\"\n", 
 "    # Preprocess image\n", 
 "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n", 
 "    \n", 
 "    # If U-Net model is available, use it for segmentation\n", 
 "    if model is not None:\n", 
 "        # Normalize image for U-Net\n", 
 "        normalized = image.astype(np.float32) / 255.0\n", 
 "        input_image = np.expand_dims(normalized, axis=0)\n", 
 "        \n", 
 "        # Get U-Net prediction\n", 
 "        prediction = model.predict(input_image)\n", 
 "        binary_mask = (prediction[0, :, :, 0] > 0.5).astype(np.uint8) * 255\n", 
 "    else:\n", 
 "        # Fallback to adaptive thresholding\n", 
 "        binary_mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n", 
 "                                          cv2.THRESH_BINARY, 11, 2)\n", 
 "    \n", 
 "    # Connected Component Analysis\n", 
 "    labeled_image, regions = connected_component_analysis(binary_mask)\n", 
 "    \n", 
 "    # Find Lines and Words\n", 
 "    lines = find_lines_and_words(regions)\n", 
 "    \n", 
 "    # Extract text using Tesseract\n", 
 "    custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz.,()%/-:'\n", 
 "    extracted_text = pytesseract.image_to_string(binary_mask, config=custom_config)\n", 
 "    \n", 
 "    return {\n", 
 "        'text': extracted_text,\n", 
 "        'binary_mask': binary_mask,\n", 
 "        'regions': regions,\n", 
 "        'lines': lines\n", 
 "    }\n", 
 "\n", 
 "# Initialize U-Net model\n", 
 "# unet = unet_model()\n", 
 "# print(\"U-Net model created\")\n", 
 "\n", 
 "print(\"Step 4: U-Net + Tesseract OCR Pipeline - Ready\")" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# 5. Parsing Regex untuk Ekstraksi Kandungan Gizi\n", 
 "import re\n", 
 "import pandas as pd\n", 
 "\n", 
 "def parse_nutritional_information(text):\n", 
 "    \"\"\"\n", 
 "    Parse nutritional information from OCR text using regex patterns\n", 
 "    \"\"\"\n", 
 "    # Clean text\n", 
 "    text = text.lower().replace('\n', ' ').replace('\t', ' ')\n", 
 "    \n", 
 "    nutritional_data = {\n", 
 "        'takaran_saji_ml': None,\n", 
 "        'jumlah_sajian_per_kemasan': None,\n", 
 "        'energi_total_kkal': None,\n", 
 "        'lemak_total_g': None,\n", 
 "        'protein_g': None,\n", 
 "        'karbohidrat_total_g': None,\n", 
 "        'gula_sugar_g': None,\n", 
 "        'garam_natrium_mg': None,\n", 
 "        'energi_akg_persen': None,\n", 
 "        'lemak_akg_persen': None,\n", 
 "        'protein_akg_persen': None,\n", 
 "        'karbohidrat_akg_persen': None,\n", 
 "        'gula_akg_persen': None,\n", 
 "        'garam_akg_persen': None\n", 
 "    }\n", 
 "    \n", 
 "    # Regex patterns for nutritional information\n", 
 "    patterns = {\n", 
 "        'takaran_saji_ml': [\n", 
 "            r'takaran\s*saji[^\d]*(\d+(?:\.\d+)?)\s*ml',\n", 
 "            r'serving\s*size[^\d]*(\d+(?:\.\d+)?)\s*ml',\n", 
 "            r'(\d+(?:\.\d+)?)\s*ml\s*per\s*serv'\n", 
 "        ],\n", 
 "        'jumlah_sajian_per_kemasan': [\n", 
 "            r'jumlah\s*sajian[^\d]*(\d+(?:\.\d+)?)',\n", 
 "            r'servings?\s*per\s*pack[^\d]*(\d+(?:\.\d+)?)',\n", 
 "            r'(\d+(?:\.\d+)?)\s*sajian'\n", 
 "        ],\n", 
 "        'energi_total_kkal': [\n", 
 "            r'energi\s*total[^\d]*(\d+(?:\.\d+)?)\s*k?cal',\n", 
 "            r'kalori[^\d]*(\d+(?:\.\d+)?)\s*k?cal',\n", 
 "            r'energy[^\d]*(\d+(?:\.\d+)?)\s*k?cal',\n", 
 "            r'(\d+(?:\.\d+)?)\s*k?cal'\n", 
 "        ],\n", 
 "        'lemak_total_g': [\n", 
 "            r'lemak\s*total[^\d]*(\d+(?:\.\d+)?)\s*g',\n", 
 "            r'total\s*fat[^\d]*(\d+(?:\.\d+)?)\s*g',\n", 
 "            r'fat[^\d]*(\d+(?:\.\d+)?)\s*g'\n", 
 "        ],\n", 
 "        'protein_g': [\n", 
 "            r'protein[^\d]*(\d+(?:\.\d+)?)\s*g'\n", 
 "        ],\n", 
 "        'karbohidrat_total_g': [\n", 
 "            r'karbohidrat\s*total[^\d]*(\d+(?:\.\d+)?)\s*g',\n", 
 "            r'total\s*carb[^\d]*(\d+(?:\.\d+)?)\s*g',\n", 
 "            r'carbohydrate[^\d]*(\d+(?:\.\d+)?)\s*g'\n", 
 "        ],\n", 
 "        'gula_sugar_g': [\n", 
 "            r'gula[^\d]*(\d+(?:\.\d+)?)\s*g',\n", 
 "            r'sugar[^\d]*(\d+(?:\.\d+)?)\s*g'\n", 
 "        ],\n", 
 "        'garam_natrium_mg': [\n", 
 "            r'garam[^\d]*(\d+(?:\.\d+)?)\s*mg',\n", 
 "            r'natrium[^\d]*(\d+(?:\.\d+)?)\s*mg',\n", 
 "            r'sodium[^\d]*(\d+(?:\.\d+)?)\s*mg',\n", 
 "            r'salt[^\d]*(\d+(?:\.\d+)?)\s*mg'\n", 
 "        ]\n", 
 "    }\n", 
 "    \n", 
 "    # AKG percentage patterns\n", 
 "    akg_patterns = {\n", 
 "        'energi_akg_persen': r'energi[^%]*(\d+(?:\.\d+)?)\s*%',\n", 
 "        'lemak_akg_persen': r'lemak[^%]*(\d+(?:\.\d+)?)\s*%',\n", 
 "        'protein_akg_persen': r'protein[^%]*(\d+(?:\.\d+)?)\s*%',\n", 
 "        'karbohidrat_akg_persen': r'karbohidrat[^%]*(\d+(?:\.\d+)?)\s*%',\n", 
 "        'gula_akg_persen': r'gula[^%]*(\d+(?:\.\d+)?)\s*%',\n", 
 "        'garam_akg_persen': r'garam[^%]*(\d+(?:\.\d+)?)\s*%'\n", 
 "    }\n", 
 "    \n", 
 "    # Extract basic nutritional values\n", 
 "    for key, pattern_list in patterns.items():\n", 
 "        for pattern in pattern_list:\n", 
 "            match = re.search(pattern, text, re.IGNORECASE)\n", 
 "            if match:\n", 
 "                try:\n", 
 "                    nutritional_data[key] = float(match.group(1))\n", 
 "                    break\n", 
 "                except (ValueError, IndexError):\n", 
 "                    continue\n", 
 "    \n", 
 "    # Extract AKG percentages\n", 
 "    for key, pattern in akg_patterns.items():\n", 
 "        match = re.search(pattern, text, re.IGNORECASE)\n", 
 "        if match:\n", 
 "            try:\n", 
 "                nutritional_data[key] = float(match.group(1))\n", 
 "            except (ValueError, IndexError):\n", 
 "                continue\n", 
 "    \n", 
 "    return nutritional_data\n", 
 "\n", 
 "def extract_nutrition_from_images(images, model=None):\n", 
 "    \"\"\"\n", 
 "    Extract nutritional information from multiple images\n", 
 "    \"\"\"\n", 
 "    results = []\n", 
 "    \n", 
 "    for i, image in enumerate(images):\n", 
 "        print(f\"Processing image {i+1}/{len(images)}...\")\n", 
 "        \n", 
 "        # OCR extraction\n", 
 "        ocr_result = ocr_with_unet_pipeline(image, model)\n", 
 "        \n", 
 "        # Parse nutritional information\n", 
 "        nutrition_data = parse_nutritional_information(ocr_result['text'])\n", 
 "        nutrition_data['image_index'] = i\n", 
 "        nutrition_data['raw_text'] = ocr_result['text']\n", 
 "        \n", 
 "        results.append(nutrition_data)\n", 
 "    \n", 
 "    return results\n", 
 "\n", 
 "print(\"Step 5: Nutritional Information Parsing - Ready\")" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# 6. Save Results\n", 
 "import json\n", 
 "import csv\n", 
 "from datetime import datetime\n", 
 "\n", 
 "def save_results_to_csv(results, filename=None):\n", 
 "    \"\"\"\n", 
 "    Save extraction results to CSV file\n", 
 "    \"\"\"\n", 
 "    if filename is None:\n", 
 "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n", 
 "        filename = f\"nutritional_extraction_results_{timestamp}.csv\"\n", 
 "    \n", 
 "    # Convert results to DataFrame\n", 
 "    df = pd.DataFrame(results)\n", 
 "    \n", 
 "    # Reorder columns for better readability\n", 
 "    column_order = [\n", 
 "        'image_index',\n", 
 "        'takaran_saji_ml',\n", 
 "        'jumlah_sajian_per_kemasan',\n", 
 "        'energi_total_kkal',\n", 
 "        'lemak_total_g',\n", 
 "        'protein_g',\n", 
 "        'karbohidrat_total_g',\n", 
 "        'gula_sugar_g',\n", 
 "        'garam_natrium_mg',\n", 
 "        'energi_akg_persen',\n", 
 "        'lemak_akg_persen',\n", 
 "        'protein_akg_persen',\n", 
 "        'karbohidrat_akg_persen',\n", 
 "        'gula_akg_persen',\n", 
 "        'garam_akg_persen',\n", 
 "        'raw_text'\n", 
 "    ]\n", 
 "    \n", 
 "    # Reorder columns if they exist\n", 
 "    existing_columns = [col for col in column_order if col in df.columns]\n", 
 "    df = df[existing_columns]\n", 
 "    \n", 
 "    # Save to CSV\n", 
 "    df.to_csv(filename, index=False, encoding='utf-8')\n", 
 "    print(f\"Results saved to: {filename}\")\n", 
 "    \n", 
 "    return filename, df\n", 
 "\n", 
 "def save_results_to_json(results, filename=None):\n", 
 "    \"\"\"\n", 
 "    Save extraction results to JSON file\n", 
 "    \"\"\"\n", 
 "    if filename is None:\n", 
 "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n", 
 "        filename = f\"nutritional_extraction_results_{timestamp}.json\"\n", 
 "    \n", 
 "    with open(filename, 'w', encoding='utf-8') as f:\n", 
 "        json.dump(results, f, indent=2, ensure_ascii=False)\n", 
 "    \n", 
 "    print(f\"Results saved to: {filename}\")\n", 
 "    return filename\n", 
 "\n", 
 "def create_summary_report(results):\n", 
 "    \"\"\n", 
 "    Create summary report of extraction results\n", 
 "    \"\"\n", 
 "    df = pd.DataFrame(results)\n", 
 "    \n", 
 "    summary = {\n", 
 "        'total_images_processed': len(results),\n", 
 "        'successful_extractions': {},\n", 
 "        'field_completion_rates': {}\n", 
 "    }\n", 
 "    \n", 
 "    # Calculate completion rates for each field\n", 
 "    numeric_fields = [\n", 
 "        'takaran_saji_ml', 'jumlah_sajian_per_kemasan', 'energi_total_kkal',\n", 
 "        'lemak_total_g', 'protein_g', 'karbohidrat_total_g',\n", 
 "        'gula_sugar_g', 'garam_natrium_mg'\n", 
 "    ]\n", 
 "    \n", 
 "    for field in numeric_fields:\n", 
 "        if field in df.columns:\n", 
 "            non_null_count = df[field].notna().sum()\n", 
 "            completion_rate = (non_null_count / len(df)) * 100\n", 
 "            summary['successful_extractions'][field] = int(non_null_count)\n", 
 "            summary['field_completion_rates'][field] = round(completion_rate, 2)\n", 
 "    \n", 
 "    return summary\n", 
 "\n", 
 "# Example usage:\n", 
 "# results = extract_nutrition_from_images(dataset_split['test']['images'])\n", 
 "# csv_filename, df = save_results_to_csv(results)\n", 
 "# json_filename = save_results_to_json(results)\n", 
 "# summary = create_summary_report(results)\n", 
 "\n", 
 "print(\"Step 6: Save Results - Ready\")" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# 7. Compare with Ground Truth (dataset-mbdk-new.csv)\n", 
 "import pandas as pd\n", 
 "import numpy as np\n", 
 "from sklearn.metrics import mean_absolute_error, mean_squared_error\n", 
 "\n", 
 "def load_ground_truth(filepath='dataset-mbdk-new.csv'):\n", 
 "    \"\"\"\n", 
 "    Load ground truth data from CSV file\n", 
 "    \"\"\"\n", 
 "    try:\n", 
 "        ground_truth = pd.read_csv(filepath)\n", 
 "        print(f\"Ground truth loaded: {len(ground_truth)} records\")\n", 
 "        print(f\"Columns: {list(ground_truth.columns)}\")\n", 
 "        return ground_truth\n", 
 "    except FileNotFoundError:\n", 
 "        print(f\"Error: File {filepath} not found\")\n", 
 "        return None\n", 
 "    except Exception as e:\n", 
 "        print(f\"Error loading ground truth: {e}\")\n", 
 "        return None\n", 
 "\n", 
 "def align_predictions_with_ground_truth(predictions_df, ground_truth_df, image_id_column='image_index'):\n", 
 "    \"\"\n", 
 "    Align prediction results with ground truth data\n", 
 "    \"\"\n", 
 "    # Merge predictions with ground truth\n", 
 "    aligned_data = pd.merge(\n", 
 "        predictions_df, \n", 
 "        ground_truth_df, \n", 
 "        left_on=image_id_column, \n", 
 "        right_index=True, \n", 
 "        how='inner',\n", 
 "        suffixes=('_pred', '_true')\n", 
 "    )\n", 
 "    \n", 
 "    print(f\"Aligned {len(aligned_data)} predictions with ground truth\")\n", 
 "    return aligned_data\n", 
 "\n", 
 "def calculate_field_accuracy(predicted_values, true_values, tolerance_percent=10):\n", 
 "    \"\"\n", 
 "    Calculate accuracy for a specific nutritional field\n", 
 "    \"\"\n", 
 "    # Remove NaN values\n", 
 "    mask = ~(pd.isna(predicted_values) | pd.isna(true_values))\n", 
 "    pred_clean = predicted_values[mask]\n", 
 "    true_clean = true_values[mask]\n", 
 "    \n", 
 "    if len(pred_clean) == 0:\n", 
 "        return {\n", 
 "            'accuracy': 0.0,\n", 
 "            'mae': float('inf'),\n", 
 "            'rmse': float('inf'),\n", 
 "            'valid_predictions': 0,\n", 
 "            'total_samples': len(predicted_values)\n", 
 "        }\n", 
 "    \n", 
 "    # Calculate tolerance-based accuracy\n", 
 "    tolerance = tolerance_percent / 100\n", 
 "    relative_errors = np.abs(pred_clean - true_clean) / np.maximum(true_clean, 1e-6)\n", 
 "    accurate_predictions = np.sum(relative_errors <= tolerance)\n", 
 "    accuracy = accurate_predictions / len(pred_clean)\n", 
 "    \n", 
 "    # Calculate error metrics\n", 
 "    mae = mean_absolute_error(true_clean, pred_clean)\n", 
 "    rmse = np.sqrt(mean_squared_error(true_clean, pred_clean))\n", 
 "    \n", 
 "    return {\n", 
 "        'accuracy': accuracy,\n", 
 "        'mae': mae,\n", 
 "        'rmse': rmse,\n", 
 "        'valid_predictions': len(pred_clean),\n", 
 "        'total_samples': len(predicted_values)\n", 
 "    }\n", 
 "\n", 
 "def compare_with_ground_truth(predictions_df, ground_truth_df):\n", 
 "    \"\"\n", 
 "    Compare predictions with ground truth and calculate metrics\n", 
 "    \"\"\n", 
 "    # Define field mappings (prediction_column: ground_truth_column)\n", 
 "    field_mappings = {\n", 
 "        'takaran_saji_ml': 'takaran_saji_ml',\n", 
 "        'jumlah_sajian_per_kemasan': 'jumlah_sajian_per_kemasan',\n", 
 "        'energi_total_kkal': 'energi_total_kkal',\n", 
 "        'lemak_total_g': 'lemak_total_g',\n", 
 "        'protein_g': 'protein_g',\n", 
 "        'karbohidrat_total_g': 'karbohidrat_total_g',\n", 
 "        'gula_sugar_g': 'gula_sugar_g',\n", 
 "        'garam_natrium_mg': 'garam_natrium_mg'\n", 
 "    }\n", 
 "    \n", 
 "    # Align data\n", 
 "    aligned_data = align_predictions_with_ground_truth(predictions_df, ground_truth_df)\n", 
 "    \n", 
 "    # Calculate metrics for each field\n", 
 "    comparison_results = {}\n", 
 "    \n", 
 "    for pred_field, true_field in field_mappings.items():\n", 
 "        pred_col = f\"{pred_field}_pred\"\n", 
 "        true_col = f\"{true_field}_true\"\n", 
 "        \n", 
 "        if pred_col in aligned_data.columns and true_col in aligned_data.columns:\n", 
 "            metrics = calculate_field_accuracy(\n", 
 "                aligned_data[pred_col], \n", 
 "                aligned_data[true_col]\n", 
 "            )\n", 
 "            comparison_results[pred_field] = metrics\n", 
 "        else:\n", 
 "            print(f\"Warning: Missing columns for {pred_field}\")\n", 
 "    \n", 
 "    return comparison_results, aligned_data\n", 
 "\n", 
 "def generate_comparison_report(comparison_results):\n", 
 "    \"\"\n", 
 "    Generate detailed comparison report\n", 
 "    \"\"\n", 
 "    print(\"\n" + \"="*80)\n", 
 "    print(\"COMPARISON WITH GROUND TRUTH REPORT\")\n", 
 "    print(\"="*80)\n", 
 "    \n", 
 "    overall_accuracy = []\n", 
 "    \n", 
 "    for field, metrics in comparison_results.items():\n", 
 "        print(f\"\n{field.upper()}:\")\n", 
 "        print(f\"  Accuracy (±10%): {metrics['accuracy']:.3f} ({metrics['accuracy']*100:.1f}%)\")\n", 
 "        print(f\"  MAE: {metrics['mae']:.3f}\")\n", 
 "        print(f\"  RMSE: {metrics['rmse']:.3f}\")\n", 
 "        print(f\"  Valid predictions: {metrics['valid_predictions']}/{metrics['total_samples']}\")\n", 
 "        \n", 
 "        if metrics['accuracy'] != 0:\n", 
 "            overall_accuracy.append(metrics['accuracy'])\n", 
 "    \n", 
 "    if overall_accuracy:\n", 
 "        avg_accuracy = np.mean(overall_accuracy)\n", 
 "        print(f\"\nOVERALL AVERAGE ACCURACY: {avg_accuracy:.3f} ({avg_accuracy*100:.1f}%)\")\n", 
 "    \n", 
 "    print(\"="*80)\n", 
 "\n", 
 "# Example usage:\n", 
 "# ground_truth = load_ground_truth('dataset-mbdk-new.csv')\n", 
 "# if ground_truth is not None:\n", 
 "#     comparison_results, aligned_data = compare_with_ground_truth(df, ground_truth)\n", 
 "#     generate_comparison_report(comparison_results)\n", 
 "\n", 
 "print(\"Step 7: Ground Truth Comparison - Ready\")" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# 8. Evaluation System (Akurasi, dll)\n", 
 "import matplotlib.pyplot as plt\n", 
 "import seaborn as sns\n", 
 "from sklearn.metrics import confusion_matrix, classification_report\n", 
 "import warnings\n", 
 "warnings.filterwarnings('ignore')\n", 
 "\n", 
 "def calculate_comprehensive_metrics(predictions_df, ground_truth_df):\n", 
 "    \"\"\n", 
 "    Calculate comprehensive evaluation metrics\n", 
 "    \"\"\n", 
 "    comparison_results, aligned_data = compare_with_ground_truth(predictions_df, ground_truth_df)\n", 
 "    \n", 
 "    # Overall metrics\n", 
 "    total_fields = len(comparison_results)\n", 
 "    valid_extractions = sum(1 for metrics in comparison_results.values() if metrics['valid_predictions'] > 0)\n", 
 "    avg_accuracy = np.mean([metrics['accuracy'] for metrics in comparison_results.values() if metrics['accuracy'] > 0])\n", 
 "    \n", 
 "    # Field-wise detection rate\n", 
 "    detection_rates = {}\n", 
 "    for field, metrics in comparison_results.items():\n", 
 "        detection_rate = metrics['valid_predictions'] / metrics['total_samples']\n", 
 "        detection_rates[field] = detection_rate\n", 
 "    \n", 
 "    # Calculate precision, recall, and F1 for each field\n", 
 "    precision_recall_f1 = {}\n", 
 "    for field, metrics in comparison_results.items():\n", 
 "        if metrics['valid_predictions'] > 0:\n", 
 "            precision = metrics['accuracy']  # Simplified: accuracy as precision\n", 
 "            recall = detection_rates[field]\n", 
 "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n", 
 "            precision_recall_f1[field] = {'precision': precision, 'recall': recall, 'f1': f1}\n", 
 "        else:\n", 
 "            precision_recall_f1[field] = {'precision': 0, 'recall': 0, 'f1': 0}\n", 
 "    \n", 
 "    evaluation_metrics = {\n", 
 "        'overall_accuracy': avg_accuracy,\n", 
 "        'field_extraction_success_rate': valid_extractions / total_fields,\n", 
 "        'total_images_evaluated': len(aligned_data),\n", 
 "        'field_wise_metrics': comparison_results,\n", 
 "        'detection_rates': detection_rates,\n", 
 "        'precision_recall_f1': precision_recall_f1\n", 
 "    }\n", 
 "    \n", 
 "    return evaluation_metrics, aligned_data\n", 
 "\n", 
 "def visualize_results(evaluation_metrics, save_plots=True):\n", 
 "    \"\"\n", 
 "    Create visualizations for evaluation results\n", 
 "    \"\"\n", 
 "    # Set up the plotting style\n", 
 "    plt.style.use('default')\n", 
 "    sns.set_palette(\"husl\")\n", 
 "    \n", 
 "    # 1. Accuracy by Field\n", 
 "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n", 
 "    \n", 
 "    # Accuracy bar plot\n", 
 "    fields = list(evaluation_metrics['field_wise_metrics'].keys())\n", 
 "    accuracies = [evaluation_metrics['field_wise_metrics'][field]['accuracy'] \n", 
 "                 for field in fields]\n", 
 "    \n", 
 "    axes[0, 0].bar(range(len(fields)), accuracies, color='skyblue')\n", 
 "    axes[0, 0].set_title('Accuracy by Nutritional Field')\n", 
 "    axes[0, 0].set_ylabel('Accuracy')\n", 
 "    axes[0, 0].set_xticks(range(len(fields)))\n", 
 "    axes[0, 0].set_xticklabels([field.replace('_', '\\n') for field in fields], rotation=45)\n", 
 "    axes[0, 0].grid(True, alpha=0.3)\n", 
 "    \n", 
 "    # Detection rates\n", 
 "    detection_rates = [evaluation_metrics['detection_rates'][field] for field in fields]\n", 
 "    axes[0, 1].bar(range(len(fields)), detection_rates, color='lightgreen')\n", 
 "    axes[0, 1].set_title('Detection Rate by Field')\n", 
 "    axes[0, 1].set_ylabel('Detection Rate')\n", 
 "    axes[0, 1].set_xticks(range(len(fields)))\n", 
 "    axes[0, 1].set_xticklabels([field.replace('_', '\\n') for field in fields], rotation=45)\n", 
 "    axes[0, 1].grid(True, alpha=0.3)\n", 
 "    \n", 
 "    # F1 scores\n", 
 "    f1_scores = [evaluation_metrics['precision_recall_f1'][field]['f1'] for field in fields]\n", 
 "    axes[1, 0].bar(range(len(fields)), f1_scores, color='orange')\n", 
 "    axes[1, 0].set_title('F1 Score by Field')\n", 
 "    axes[1, 0].set_ylabel('F1 Score')\n", 
 "    axes[1, 0].set_xticks(range(len(fields)))\n", 
 "    axes[1, 0].set_xticklabels([field.replace('_', '\\n') for field in fields], rotation=45)\n", 
 "    axes[1, 0].grid(True, alpha=0.3)\n", 
 "    \n", 
 "    # Overall metrics summary\n", 
 "    metrics_summary = [\n", 
 "        evaluation_metrics['overall_accuracy'],\n", 
 "        evaluation_metrics['field_extraction_success_rate'],\n", 
 "        np.mean(detection_rates),\n", 
 "        np.mean(f1_scores)\n", 
 "    ]\n", 
 "    metric_labels = ['Overall\\nAccuracy', 'Field Success\\nRate', 'Avg Detection\\nRate', 'Avg F1\\nScore']\n", 
 "    \n", 
 "    axes[1, 1].bar(range(len(metric_labels)), metrics_summary, color='purple')\n", 
 "    axes[1, 1].set_title('Overall Performance Metrics')\n", 
 "    axes[1, 1].set_ylabel('Score')\n", 
 "    axes[1, 1].set_xticks(range(len(metric_labels)))\n", 
 "    axes[1, 1].set_xticklabels(metric_labels)\n", 
 "    axes[1, 1].grid(True, alpha=0.3)\n", 
 "    \n", 
 "    plt.tight_layout()\n", 
 "    \n", 
 "    if save_plots:\n", 
 "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n", 
 "        plt.savefig(f'evaluation_results_{timestamp}.png', dpi=300, bbox_inches='tight')\n", 
 "        print(f\"Evaluation plots saved as evaluation_results_{timestamp}.png\")\n", 
 "    \n", 
 "    plt.show()\n", 
 "\n", 
 "def generate_evaluation_report(evaluation_metrics):\n", 
 "    \"\"\n", 
 "    Generate comprehensive evaluation report\n", 
 "    \"\"\n", 
 "    print(\"\n" + \"="*100)\n", 
 "    print(\"COMPREHENSIVE EVALUATION REPORT\")\n", 
 "    print(\"="*100)\n", 
 "    \n", 
 "    # Overall metrics\n", 
 "    print(f\"\nOVERALL PERFORMANCE:\")\n", 
 "    print(f\"  • Overall Accuracy: {evaluation_metrics['overall_accuracy']:.3f} ({evaluation_metrics['overall_accuracy']*100:.1f}%)\")\n", 
 "    print(f\"  • Field Extraction Success Rate: {evaluation_metrics['field_extraction_success_rate']:.3f} ({evaluation_metrics['field_extraction_success_rate']*100:.1f}%)\")\n", 
 "    print(f\"  • Total Images Evaluated: {evaluation_metrics['total_images_evaluated']}\")\n", 
 "    \n", 
 "    # Field-wise detailed metrics\n", 
 "    print(f\"\nFIELD-WISE DETAILED METRICS:\")\n", 
 "    print(\"-" * 100)\n", 
 "    print(f\"{'Field':<25} {'Accuracy':<10} {'Detection':<10} {'Precision':<10} {'Recall':<10} {'F1':<10} {'Valid/Total':<12}\")\n", 
 "    print(\"-" * 100)\n", 
 "    \n", 
 "    for field in evaluation_metrics['field_wise_metrics'].keys():\n", 
 "        metrics = evaluation_metrics['field_wise_metrics'][field]\n", 
 "        prf1 = evaluation_metrics['precision_recall_f1'][field]\n", 
 "        detection = evaluation_metrics['detection_rates'][field]\n", 
 "        \n", 
 "        print(f\"{field:<25} {metrics['accuracy']:<10.3f} {detection:<10.3f} \\n\"\n", 
 "              f\"{prf1['precision']:<10.3f} {prf1['recall']:<10.3f} {prf1['f1']:<10.3f} \\n\"\n", 
 "              f\"{metrics['valid_predictions']}/{metrics['total_samples']:<12}\")\n", 
 "    \n", 
 "    # Performance classification\n", 
 "    avg_accuracy = evaluation_metrics['overall_accuracy']\n", 
 "    if avg_accuracy >= 0.9:\n", 
 "        performance_level = \"EXCELLENT\"\n", 
 "    elif avg_accuracy >= 0.8:\n", 
 "        performance_level = \"GOOD\"\n", 
 "    elif avg_accuracy >= 0.7:\n", 
 "        performance_level = \"FAIR\"\n", 
 "    else:\n", 
 "        performance_level = \"NEEDS IMPROVEMENT\"\n", 
 "    \n", 
 "    print(f\"\nPERFORMANCE LEVEL: {performance_level}\")\n", 
 "    print(\"="*100)\n", 
 "\n", 
 "def run_complete_evaluation(images, ground_truth_path='dataset-mbdk-new.csv', model=None):\n", 
 "    \"\"\n", 
 "    Run complete evaluation pipeline\n", 
 "    \"\"\n", 
 "    print(\"Starting complete evaluation pipeline...\")\n", 
 "    \n", 
 "    # 1. Extract nutritional information\n", 
 "    print(\"\n1. Extracting nutritional information...\")\n", 
 "    results = extract_nutrition_from_images(images, model)\n", 
 "    \n", 
 "    # 2. Save results\n", 
 "    print(\"\n2. Saving results...\")\n", 
 "    csv_filename, predictions_df = save_results_to_csv(results)\n", 
 "    \n", 
 "    # 3. Load ground truth\n", 
 "    print(\"\n3. Loading ground truth...\")\n", 
 "    ground_truth = load_ground_truth(ground_truth_path)\n", 
 "    \n", 
 "    if ground_truth is None:\n", 
 "        print(\"Cannot proceed without ground truth data.\")\n", 
 "        return None\n", 
 "    \n", 
 "    # 4. Calculate evaluation metrics\n", 
 "    print(\"\n4. Calculating evaluation metrics...\")\n", 
 "    evaluation_metrics, aligned_data = calculate_comprehensive_metrics(predictions_df, ground_truth)\n", 
 "    \n", 
 "    # 5. Generate reports and visualizations\n", 
 "    print(\"\n5. Generating evaluation report...\")\n", 
 "    generate_evaluation_report(evaluation_metrics)\n", 
 "    \n", 
 "    print(\"\n6. Creating visualizations...\")\n", 
 "    visualize_results(evaluation_metrics)\n", 
 "    \n", 
 "    return evaluation_metrics, aligned_data\n", 
 "\n", 
 "# Example usage:\n", 
 "# evaluation_metrics, aligned_data = run_complete_evaluation(\n", 
 "#     dataset_split['test']['images'], \n", 
 "#     'dataset-mbdk-new.csv'\n", 
 "# )\n", 
 "\n", 
 "print(\"Step 8: Comprehensive Evaluation System - Ready\")\n", 
 "print(\"\n" + \"="*80)\n", 
 "print(\"ALL STEPS COMPLETED - OCR NUTRITIONAL EXTRACTION PROGRAM READY\")\n", 
 "print(\"="*80)" 
 ] 
 } 
 ], 
 "metadata": { 
 "kernelspec": { 
 "display_name": "Python 3", 
 "language": "python", 
 "name": "python3" 
 }, 
 "language_info": { 
 "codemirror_mode": { 
 "name": "ipython", 
 "version": 3 
 }, 
 "file_extension": ".py", 
 "mimetype": "text/x-python", 
 "name": "python", 
 "nbconvert_exporter": "python", 
 "pygments_lexer": "ipython3", 
 "version": "3.8.5" 
 } 
 }, 
 "nbformat": 4, 
 "nbformat_minor": 4 
}